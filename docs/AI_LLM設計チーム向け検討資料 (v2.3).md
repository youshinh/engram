# **AI/LLM設計チーム向け検討資料 (v2.3)**

## **新長期記憶構想「en:RAG」導入検討資料** **（Engrammer自己学習ループ搭載）**

---

## **1\. 背景：en:gram のパラドックスと「情報の飽和」**

* **名称変更の確認:** 本資料では、自己学習システム「ACE」の正式名称を、新しい呼称である「 **Engrammer** 」として記述します。  
* **en:gram の本質的課題（パラドックス）:**  
  * **ユーザーの脳（経験豊かな脳）:** 経験を積むと「**スキーマ駆動型（トップダウン処理）**」に移行し、物事の「要点」で効率的に処理します。この過程で、詳細な感覚情報（＝**ノイズ**）は自動的に切り捨てられます。  
  * **en:gram の役割（若い脳）:** en:gram の思想「**ノイズにこそ宇宙は宿る**」は、このユーザーが切り捨てた「ノイズ」をありのままに記録すること（**データ駆動型（ボトムアップ処理）**）を意味します。  
* **パラドックス:** `en:gram` が忠実にノイズを記録し続けると、その長期記憶は「**ノイズの海**」となり、「**情報の飽和**」状態に陥ります。現在のRAG（検索拡張生成）では、この飽和したノイズから必要な「響き」を発見できず、`Insight Bloom` 機能が破綻します。

## **2\. en:RAGの設計思想：脳の二面性の模倣**

このパラドックスを解決するため、AI基盤側が「経験豊かな脳（トップダウン処理）」の役割を担い、脳の二面性を模倣します。

* **`en:gram`（アプリ）:** 「ノイズ」を収集・記録する（若い脳）。  
* **`en:RAG`（AI基盤）:** `en:gram` が収集したノイズの海から「**スキーマ（要点）**」を生成し、「意味のネットワーク」を構築する（経験豊かな脳）。

## **3\. en:RAGの機能と実装プロセス（3ステップ）**

従来のRAGに「記憶の生成」ステップを追加します。

1. **区切る (Segment):** 思考のストリームを「出来事（エピソード）」単位で動的にグルーピングする。  
2. **要約する (Summarize / Schematize):** グループ化されたエピソードの「響きの本質（スキーマ）」をLLMで生成する。  
3. **繋げる (Network):** 生成したスキーマをベクトル化し、元のノイズ群への参照を保持したままネットワーク化する。

## **4\. メリット**

* **「情報の飽和」の根本的解決:** 検索対象が「生のノイズ」から「**要約されたスキーマ**」に変わるため、思考の断片が増えても検索品質と速度が低下しません。  
* **「響き」の発見精度の飛躍的向上:** 異質なノイズも抽象化された「スキーマ」同士として比較できるため、ユーザーも気づかなかった「響き」を高精度で発見できます。  
* **`Engrammer` の学習効率化:** 自己学習システムの学習データが「点と点の学習」から「**スキーマとスキーマの学習**」になり、ユーザーの感性のパターンをより効率的に学べます。

## **5\. 実装上の懸念**

1. **哲学的懸念：「ノイズ」の損失リスク**  
   * 「ノイズにこそ宇宙は宿る」という哲学に対し、「要約（スキーマ化）」が「ノイズ」を切り捨て、宇宙の豊かさを損なう危険性があります。  
2. **技術的懸念：「区切り方」の難易度**  
   * `en:gram` の入力は非同期かつ多様です。「いつからいつまでを一つのエピソードとするか」の「**イベント境界**」を自動定義するロジックは非常に困難です。  
3. **アーキテクチャ的懸念：「ローカルファースト」との両立**  
   * エピソードを「要約」する処理はLLMの推論を必要とし、これを「ローカルファースト」（オンデバイスAI）で高頻度に実行するのは非現実的です。

## **6\. アーキテクチャ概念図（v2.3）**

`en:RAG`基盤は、3つの主要ループを持つ。

1. **発見（Read）ループ:** ユーザーの「共鳴」を発見する。  
2. **生成（Write）ループ:** 「スキーマ」を生成・強化する。  
3. **学習（Learn）ループ:** 「逸脱（アノマリー）」から新しいスキーマを発見する。

graph TD

    subgraph en:gram アプリ

        A\[入力: ノイズ\] \--\> B(ノイズの海 DB);

        B \--\> C{ベクトル化};

        C \--\> D\[ベクトル DB (ノイズ)\];

    end

    subgraph en:RAG 基盤 / Engrammer

        subgraph "共有エンジン"

            CE(トピック・クラスタリング・エンジン);

            D \-- "全ノイズ" \--\> CE;

            H \-- "全スキーマ" \--\> CE;

            AN\_DB \-- "全アノマリー" \--\> CE;

        end

        subgraph "ループ1：発見（Read）"

            IB(Insight Bloom) \-- "響きの候補" \--\> U\[ユーザー\];

            CE \-- "トピック/アノマリー" \--\> IB;

            U \-- "共鳴 (Reflect)" \--\> E1(イベント境界 確定);

            E1 \--\> S\_Trigger(スキーマ生成 起動);

        end

        subgraph "ループ2：生成（Write）"

            S\_Trigger \-- "ノイズ群" \--\> SR(スキーマRAG);

            CE \-- "トピック情報" \--\> SR;

            SR \-- "最適なお手本" \--\> LLM(LLM スキーマ化);

            LLM \-- "新スキーマ ＋ 【メタ・スキーマ】" \--\> F(スキーマ DB);

            F \--\> G{ベクトル化};

            G \--\> H\[ベクトル DB (スキーマ)\];

            LLM \-- "【逸脱ノイズ】" \--\> AN\_DB(アノマリー DB);

        end

        subgraph "ループ3：学習（Learn）"

            AN\_DB \--\> AN\_Vec{ベクトル化};

            AN\_Vec \--\> AN\_VDB\[ベクトル DB (アノマリー)\];

            AN\_VDB \-- "全アノマリー" \--\> CE;

            CE \-- "【新アノマリー・クラスター発見】" \--\> S\_Trigger;

        end

    end

## **7\. en:gram への最適化案（懸念点の解消）**

上記の懸念点を解消し、アーキテクチャを実現するため、以下の6つの提案を段階的に組み込みます。

### **提案1：「区切り」を Engrammer の「共鳴」に委ねる（イベント駆動型）**

* **懸念解消（1, 2）:** 「区切り方」の難しさ（懸念2）を解決するため、AIによる自動定義を放棄します。`en:gram` にとっての「エピソード」とは、`Insight Bloom` が「響き」を発見し、ユーザーがそれに「**共鳴（Reflect）**」した瞬間です。  
* **アプローチ:** ユーザーの「共鳴」こそが「予期せぬ新規性の発見」を意味する主観的なシグナル（イベント境界）となります。AIはこのトリガーに基づき、関連するノイズ群を「区切り」ます。

### **提案2：要約を「索引」として扱い、ノイズは保持する**

* **懸念解消（1）:** 哲学的懸念（ノイズの損失）を解消します。  
* **アプローチ:** 生成された「スキーマ（要約）」は、高速検索のための「**索引（インデックス）**」として使用します。ユーザーが「響き」（スキーマ）を選択したら、それに紐づく「**元のノイズ群**」を提示することで、ノイズの豊かさを失いません。

### **提案3：「記憶の生成」処理を非同期化する**

* **懸念解消（3）:** ローカルファーストとの両立（懸念3）を図ります。  
* **アプローチ:** 重い「スキーマ化」のLLM推論や、後述の「クラスタリング」処理は、デバイスのアイドル時や充電時に、ローカル（Gemini Nano）またはクラウド（Genkit）を活用した**非同期のバッチ処理**として実行します。

### **提案4：トピック・クラスタリング・エンジンによる「響きの候補」の能動的発見**

* **役割（発見ループ）:** `提案1` の「共鳴」を待つ受動的なアプローチを補完します。  
* **アプローチ:** 蓄積された「ノイズDB」の全ベクトルデータを非同期でクラスタリングし、「**隠れたトピック（響きの候補）**」（例: "仕事のプレッシャー"）をAIが能動的に発見します。  
* **メリット:** この「響きの候補」を `Insight Bloom` がユーザーに提示することで、`提案1` の「共鳴」を能動的に誘発させることができます。

### **提案5：クラスタリングとスキーマRAGの統合（生成ループの最適化）**

* **役割（生成ループ）:** `提案4` のクラスタリング結果を、「スキーマ生成（Write）」のプロセスに応用し、`Context Engineering` の一環として生成品質と効率を最大化します。  
* **目的:** 「スキーマRAG」（高品質なスキーマ生成のために関連スキーマを検索する技術）実行時の**検索空間を最適化**し、低コストと高品質（一貫性）を両立させます。  
* **アプローチ:**  
  1. スキーマ生成時、まず対象のノイズ群を `クラスタリング・エンジン` で「トピック分類」します（例: "トピックID: C-007"）。  
  2. `スキーマRAG` の検索対象を `スキーマDB` 全体ではなく、**「トピックID: C-007」にタグ付けされたスキーマ群**に限定します。  
* **メリット:** 検索負荷（コスト）が劇的に低下し、参照するお手本（コンテキスト）の精度が上がるため、生成されるスキーマの「**一貫性**」が担保されます。

### **提案6：メタ・スキーマによる逸脱（アノマリー）の再抽象化（自己学習ループ）**

* **役割（学習ループ）:** `Engrammer`（自己学習システム）の中核機能として、AIが自らの「盲点」から学習するループを導入し、抽象化の**品質**そのものを自律的に向上させます。  
* **目的:** AIが生成した「スキーマ」からこぼれ落ちた「**逸脱ノイズ（アノマリー）**」を「新しい響きの原石」として捉え直し、これを新しいスキーマへと昇格させます。  
* **アプローチ:**  
  1. **メタ・スキーマの生成:** `提案5` でLLMがスキーマを生成する際、構造化出力を用い、スキーマ本体と同時に「**メタ・スキーマ**」（`信頼度スコア`、`逸脱ノイズ`のリスト）を生成させます。  
  2. **アノマリー・ネットワークの構築:** 抽出された「逸脱ノイズ」を専用の `アノマリー DB` にベクトル化して蓄積します。  
  3. **逸脱の分析:** `クラスタリング・エンジン（提案4）` は、この `アノマリー DB` も定期的に分析します。  
  4. **「逸脱」から「スキーマ」への昇格:** 「逸脱ノイズ」群が新しいクラスターを形成した場合、AIはこれを「**AIが発見した新しい概念**」とみなし、`スキーマ生成トリガー` を起動。`スキーマRAG` を経て、`スキーマDB`に正式に昇格させます。  
* **メリット:** 哲学的懸念（1）を完全に解消します。「スキーマからこぼれ落ちたノイズ」こそをAIが進化するための「教師データ」として扱うことで、AIは自律的に抽象化能力を深化させ、真の「予期せぬ響き」を創出します。


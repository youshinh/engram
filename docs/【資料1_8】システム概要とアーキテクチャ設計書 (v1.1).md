# **【資料1/8】システム概要とアーキテクチャ設計書 (v1.1)**

## **1\. 概要と目的**

en:gram は、ユーザーのプライベートな思考（ノート）を、デバイス上で安全に分析し、予期せぬ繋がりを発見・提案する「知的創造パートナー」アプリケーションである。

**Google Chrome Built-in AI Challenge 2025** \[cite: hackathon\_rules.md\] への提出を目的とし、以下の設計思想に基づき構築する。

* **ローカルファースト:** ユーザーの思考データ（Note, Relationエンティティ\[cite: engram\_database\_design\_v1.1.md\]）は、原則としてクライアントサイド（IndexedDB / Dexie.js\[cite: db.ts\]）に保存される \[cite: Agents.md\]。  
* **ハイブリッドAI:** プライバシーと即時性のため、まずオンデバイスAI（Gemini Nano \[cite: hackathon\_rules.md\]）での処理を試みる。より高度な分析やフォールバックが必要な場合のみ、クラウドAIを利用する \[cite: spec.md\]。  
* **自己改善 (Engrammer):** バックエンドのAI（engrammerFlow\[cite: engram\_backend\_api\_design\_v1.1.ts\]）は、単なる応答生成器ではなく、LangGraph.js 1.0\[cite: LangChain/LangGraph 1.0 詳細調査計画\]を基盤とした自己改善エージェント「**Engrammer**」であり、ユーザーのフィードバックから学習し「プレイブック」\[cite: ACEアルゴリズムJavaScript実装ガイド.md\]を進化させる。

## **2\. 技術スタック**

* **フロントエンド:** React (v18+), Vite, TypeScript (v5+)  
* **クライアントDB:** Dexie.js (v4+)\[cite: db.ts\] (IndexedDB ラッパー)  
* **バックエンド:** Firebase Cloud Functions (Node.js 20\) \[cite: firebase.ts\]  
* **AI (クライアント):** window.ai (Gemini Nano, Prompt API) \[cite: hackathon\_rules.md, App.tsx\]  
* **AI (バックエンド):** Google AI SDK (Gemini Pro/Flash), Vertex AI (Multimodal Embedding API)  
* **AIオーケストレーション:** **LangGraph.js 1.0** \[cite: LangChain/LangGraph 1.0 詳細調査計画\] (Engrammer のコア・ランタイム)  
* **UIライブラリ:** reactflow (グラフビュー用), react-canvas-draw (スケッチ用), @react-three/fiber (3Dモデル用)

## **3\. アーキテクチャ設計 (v1.1)**

LangGraph 1.0\[cite: LangChain/LangGraph 1.0 詳細調査計画\]の先進的な機能（非同期実行、耐久性、マルチエージェント）を全面的に採用し、アーキテクチャをv1.1に更新する。

### **3.1. 全体構成図 (v1.1)**

en:gram は、以下の3つの主要コンポーネントで構成される。

1. **React SPA (クライアント):**  
   * UI / UX（すりガラスデザイン\[cite: d.png, l.png\]、グラフビュー）  
   * ローカルDB (Dexie.js)\[cite: db.ts\]  
   * オンデバイスAI (getInsightSuggestions)\[cite: engram\_client\_ai\_logic\_v1.1.md\]  
   * バックグラウンド同期ワーカー (App.tsx\[cite: App.tsx\]のuseEffect)  
   * Engrammer 非同期ポーリングクライアント (useEngrammerFlow フック)  
2. **Firebase Services (バックエンド基盤):**  
   * **Cloud Functions:** LangGraph.js で構築された Engrammer の実行環境 (engrammerFlow\[cite: engram\_backend\_api\_design\_v1.1.ts\]) および、その他API (embedNote, findConnectionsCloud\[cite: engram\_backend\_api\_design\_v1.1.ts\])。  
   * **Firestore:** **LangGraph Checkpointer** \[cite: LangChain/LangGraph 1.0 詳細調査計画\] の永続化ストアとして利用。Engrammer の「プレイブック」を含む AgentState を thread\_id ごとに保存する。  
   * **Authentication:** APIの認証基盤。  
3. **Google AI Services (AIモデル):**  
   * Gemini Pro/Flash (スーパーバイザー、各エージェント用)  
   * Vertex AI Multimodal Embedding (Embedding API用)

### **3.2. コア・アーキテクチャの変更点 (v1.1)**

#### **3.2.1. Engrammer の非同期・耐久実行 (改善案\#2)**

ユーザー体験（UX）\[cite: hackathon\_rules.md\]を向上させるため、Engrammer\[cite: engram\_ace\_integration\_design\_v1.1.md\] との対話フローを「同期待ち受け」から「**非同期実行・状態ポーリング**」に変更する。（詳細は【資料6/8】\[cite: engram\_ace\_integration\_design\_v1.1.md\]にて定義）

* **旧フロー:** クライアントが callAceFlow\[cite: App.tsx\] → aceFlow\[cite: firebase.ts\] が全処理（Generator, Reflector, Curator）\[cite: ACEアルゴリズムJavaScript実装ガイド.md\]を実行 → クライアントがMarkdownを受け取る（数秒待機）。  
* **新フロー (v1.1):**  
  1. クライアントが engrammerFlow\_start\[cite: engram\_backend\_api\_design\_v1.1.ts\] API を呼び出す。  
  2. Firebase Function は LangGraph の実行を開始し、即座に { threadId }\[cite: LangChain/LangGraph 1.0 詳細調査計画\] をクライアントに**即時応答**する。  
  3. クライアント（App.tsx\[cite: App.tsx\]）は、受け取った threadId を使い、getEngrammerState\[cite: engram\_backend\_api\_design\_v1.1.ts\] API を定期的にポーリング（またはWebSocketでリッスン）する。  
  4. Engrammer\[cite: engram\_backend\_api\_design\_v1.1.ts\] はバックグラウンドで Generator\[cite: ACEアルゴリズムJavaScript実装ガイド.md\] ノードを実行。Checkpointer\[cite: LangChain/LangGraph 1.0 詳細調査計画\] が Generator の分析結果を Firestore に永続化する。  
  5. クライアントはポーリングにより Generator の結果（latestResponse）と status: 'interrupted'\[cite: engram\_ace\_integration\_design\_v1.1.md\] を検知し、即座にUI（MainPage.tsx\[cite: MainPage.tsx\]）に分析結果を表示する。  
  6. Engrammer\[cite: engram\_backend\_api\_design\_v1.1.ts\] は HITL\[cite: LangChain/LangGraph 1.0 詳細調査計画\]（ユーザーの承認待ち）のため一時停止する。

#### **3.2.2. Engrammer のマルチエージェント（スーパーバイザー）化 (改善案\#4)**

engrammerFlow\[cite: engram\_backend\_api\_design\_v1.1.ts\] を、単一機能のグラフから、タスクを振り分ける「**スーパーバイザー・アーキテクチャ**」\[cite: LangChain/LangGraph 1.0 詳細調査計画\]に進化させる。（詳細は【資料7/8】\[cite: engram\_backend\_api\_design\_v1.1.ts\]にて定義）

* Engrammer\[cite: engram\_backend\_api\_design\_v1.1.ts\] は「スーパーバイザー」ノードとして機能する。  
* ユーザーの query\[cite: engram\_ace\_integration\_design\_v1.1.md\] の内容を解釈し、処理を専門のサブエージェント（LangGraph Subgraphs\[cite: LangChain/LangGraph 1.0 詳細調査計画\]）に振り分ける。  
  * 例: 「この木材\[cite: user\_provided\_info\]は何？」 → WoodworkingAgent（外部ツール\[cite: 複合機能提案\]連携）  
  * 例: 「ノートを要約して」 → SummarizationAgent  
  * 例: 「新しい繋がりは？」 → GeneratorAgent（従来のGenerator\[cite: ACEアルゴリズムJavaScript実装ガイド.md\]）  
* スーパーバイザーは各エージェントの結果を収集・統合し、最終的な回答を AgentState\[cite: engram\_backend\_api\_design\_v1.1.ts\] の messages に追加する。

#### **3.2.3. ヒューマンインザループ (HITL) の導入 (改善案\#1)**

LangGraph の interrupt（一時停止）機能\[cite: LangChain/LangGraph 1.0 詳細調査計画\]を活用し、ユーザーが AI の学習に介入できる「**対話型学習**」を導入する。（詳細は【資料6/8】\[cite: engram\_ace\_integration\_design\_v1.1.md\], 【資料7/8】\[cite: engram\_backend\_api\_design\_v1.1.ts\]にて定義）

* Reflector\[cite: ACEアルゴリズムJavaScript実装ガイド.md\] が洞察（pendingInsights\[cite: engram\_backend\_api\_design\_v1.1.ts\]）を生成した後、グラフは一時停止する。  
* クライアント（MainPage.tsx\[cite: MainPage.tsx\]）は、ポーリングにより「status: 'interrupted'」と pendingInsights を検知し、「この洞察を学習させますか？」というUIを表示する（複合機能\#14）。  
* ユーザーが「はい」を押すと、クライアントは engrammerFlow\_continue\[cite: engram\_backend\_api\_design\_v1.1.ts\] API を呼び出し、グラフを再開させ、Curator\[cite: ACEアルゴリズムJavaScript実装ガイド.md\] がプレイブックを更新する。

## **4\. 非機能要件 (v1.1)**

* **パフォーマンス:**  
  * オンデバイスAI (getInsightSuggestions\[cite: engram\_client\_ai\_logic\_v1.1.md\])： p95で500ms未満 \[cite: research.md\]。  
  * Engrammer\[cite: engram\_backend\_api\_design\_v1.1.ts\] の初期応答（engrammerFlow\_start\[cite: engram\_backend\_api\_design\_v1.1.ts\] 呼び出しから Generator\[cite: ACEアルゴリズムJavaScript実装ガイド.md\] の結果表示まで）： p95で2秒未満。（非同期化により達成）  
* **スコープ:** シングルユーザーアプリケーション \[cite: research.md\]。ローカルDBは10,000ノート規模での動作を保証 \[cite: research.md\]。  
* **セキュリティ:** APIキーは .env\[cite: engram\_setup\_guide\_v1.1.md\] から読み込み、Firebase Secret Manager で管理する \[cite: Agents.md\]。クライアントDBのデータが（オプトインの同期機能\[cite: spec.md\]以外で）クラウドに送信されないことを保証する。  
* **耐久性 (v1.1 新規):**  
  * LangGraph Checkpointer\[cite: LangChain/LangGraph 1.0 詳細調査計画\]（Firestore）により、Engrammer\[cite: engram\_backend\_api\_design\_v1.1.ts\] のバックグラウンド処理は、Cloud Function のタイムアウトや一時的なエラーが発生しても、中断箇所から安全に再開可能でなければならない。  
* **安全性 (v1.1 新規):**  
  * LangGraph Middleware\[cite: LangChain/LangGraph 1.0 詳細調査計画\]（改善案\#3）を Engrammer\[cite: engram\_backend\_api\_design\_v1.1.ts\] に実装し、LLMの総呼び出し回数に制限を設け、無限ループや意図しない高額請求を防ぐ。

